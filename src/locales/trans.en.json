{
    "about-experiment": "You can register data and browse the model with the optimal parameters for it. Each experiment can be performed within the available container resources.",
    "about-sources": "You can register a file, or use an existing registered data source for a new experiment.",
    "fail-preprocess": "Failed to pre-process.",
    "about-preprocess": "Customize the options as your preference, and press Run AutoML to preprocess the dataset and start modelling!",
    "waiting-preprocess": "This dataset is waiting to be pre-processed.",
    "done-preprocess": "This dataset has been pre-processed.",
    "no-split": "This data has not been splitted yet. you can check it after running AutoML.",
    "random-split": "Split the data randomly.",
    "number-container": "No. of Containers",
    "number-container-description": "Number of containers to be used for modelling.",
    "about-leaderboard": "Check the highest evaluated model pipelines order by the metric selected.",
    "about-model-evaluation": "You can see additional statistics about the model.",
    "about-modelbinary": "The model binary files can be used in individual environments using the pickle library. \nIt requires python 3.7 or higher, scikit-learn==0.22.1, Autoinsight module(optional)",
    "about-ohe": "Categorical or Object columns (e.g. texts) used as Features in the experiment are One-Hot-Encoded if this option is checked.\nOtherwise, categorical columns are encoded into integers (Label Encoding).\n[Note] One Hot Encoding converts each category of a column into binary columns that can lead to a larger dataset.",
    "about-varthreshold": "Preprocessor finds out the features with their variances lower than the standard (0 by default), \nand deletes those features with low or no predictive power.",
    "about-scaling": "Preprocessor scales or standardizes the entire features by the selected method, which can lead to better results in certain models.",
    "about-featureengineering": "Feature Engineering methods including Feature Selection and Dimension Reduction are applied to improve the or boost the performance for a high-dimensional dataset.\n[Note] Some of these methods including matrix decomposition or kernel approximation can convert the shape of whole features.",
    "about-corr": "A correlation matrix is a table showing correlation coefficients between variables. Each cell in the table shows the correlation between two variables. A correlation matrix is used to summarize data, as an input into a more advanced analysis, and as a diagnostic for advanced analyses.",
    "about-pairplot": "A pairplot plot a pairwise relationships in a dataset. A pairplot allows us to see both distribution of single variables and relationships between two variables. and used to understand the relationship or pattern between two variables or dimensions in our dataset.",
    "about-parcoord": "parallel_coordinates, each row of the DataFrame is represented by a polyline mark which traverses a set of parallel axes, one for each of the dimensions. This plot is interactive so you can drag the lines along the axes to filter regions.",
    "about-parcate": "parallel_coordinates, each row of the DataFrame is represented by a polyline mark which traverses a set of parallel axes, one for each of the dimensions. This plot is interactive so you can drag the lines along the axes to filter regions.",
    "about-tagging": "Tagging results will be added as a new column of the dataset during the preprocessing.",
    "about-helper-package": "Some preprocessors need our own helper packages. You have to download and install this.",
    "ModelCnt": "Models",
    "DepCnt": "Dep.",
    "colCount": "Columns"
}